{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import important libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\User\\anaconda3\\envs\\torchreid2\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['resnet18', 'resnet34', 'resnet50', 'resnet101', 'resnet152', 'resnext50_32x4d', 'resnext101_32x8d', 'resnet50_fc512', 'se_resnet50', 'se_resnet50_fc512', 'se_resnet101', 'se_resnext50_32x4d', 'se_resnext101_32x4d', 'densenet121', 'densenet169', 'densenet201', 'densenet161', 'densenet121_fc512', 'inceptionresnetv2', 'inceptionv4', 'xception', 'resnet50_ibn_a', 'resnet50_ibn_b', 'nasnsetmobile', 'mobilenetv2_x1_0', 'mobilenetv2_x1_4', 'shufflenet', 'squeezenet1_0', 'squeezenet1_0_fc512', 'squeezenet1_1', 'shufflenet_v2_x0_5', 'shufflenet_v2_x1_0', 'shufflenet_v2_x1_5', 'shufflenet_v2_x2_0', 'mudeep', 'resnet50mid', 'hacnn', 'pcb_p6', 'pcb_p4', 'mlfn', 'osnet_x1_0', 'osnet_x0_75', 'osnet_x0_5', 'osnet_x0_25', 'osnet_ibn_x1_0', 'osnet_ain_x1_0', 'osnet_ain_x0_75', 'osnet_ain_x0_5', 'osnet_ain_x0_25']\n"
     ]
    }
   ],
   "source": [
    "import torchreid\n",
    "import numpy as np\n",
    "import sklearn.model_selection\n",
    "from __future__ import absolute_import\n",
    "from __future__ import print_function\n",
    "from __future__ import division\n",
    "import torch\n",
    "\n",
    "from torchreid.models import build_model\n",
    "import torch.nn as nn\n",
    "from torchreid.utils import FeatureExtractor\n",
    "from torch.nn import functional as F\n",
    "from torchreid import metrics\n",
    "\n",
    "import glob\n",
    "import os.path as osp\n",
    "\n",
    "from torchreid.data import ImageDataset\n",
    "torchreid.models.show_avai_models()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.12.1+cu113'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Check if GPU is being used\n",
    "\n",
    "torch.cuda.is_available()\n",
    "torch.cuda.device_count()\n",
    "torch.cuda.get_device_name(0)\n",
    "torch. __version__"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Register Occluded-Reid into the dataset list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchreid.data import ImageDataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "class OccludedREID(ImageDataset):\n",
    "    dataset_dir = 'occluded_reid'\n",
    "\n",
    "    def __init__(self, root='', split_ratio=0.5, **kwargs):\n",
    "        self.root = osp.abspath(osp.expanduser(root))\n",
    "        self.occluded_dir = osp.join(self.root, self.dataset_dir, 'occluded_body_images')\n",
    "        self.whole_dir = osp.join(self.root, self.dataset_dir, 'whole_body_images')\n",
    "\n",
    "        pid_container = self._get_pid_container(self.whole_dir)\n",
    "        train_pids, test_pids = train_test_split(list(pid_container), test_size=split_ratio, random_state=42)\n",
    "\n",
    "        train = self._process_dir(self.whole_dir, train_pids, relabel=True)\n",
    "        gallery = self._process_dir(self.whole_dir, test_pids, relabel=False)\n",
    "        query = self._process_dir(self.occluded_dir, test_pids, relabel=False)\n",
    "\n",
    "        super(OccludedREID, self).__init__(train, query, gallery, **kwargs)\n",
    "\n",
    "    def _get_pid_container(self, dir_path):\n",
    "        img_paths = glob.glob(osp.join(dir_path, '*', '*.tif'))\n",
    "\n",
    "        pid_container = set()\n",
    "        for img_path in img_paths:\n",
    "            pid = int(osp.basename(osp.dirname(img_path)))\n",
    "            pid_container.add(pid)\n",
    "\n",
    "        return pid_container\n",
    "\n",
    "    def _process_dir(self, dir_path, pids, relabel=False):\n",
    "        img_paths = glob.glob(osp.join(dir_path, '*', '*.tif'))\n",
    "\n",
    "        pid2label = {pid: label for label, pid in enumerate(pids)}\n",
    "\n",
    "        dataset = []\n",
    "        for img_path in img_paths:\n",
    "            pid = int(osp.basename(osp.dirname(img_path)))\n",
    "            if pid not in pids: continue\n",
    "            if relabel: pid = pid2label[pid]\n",
    "            img_name = osp.basename(img_path)\n",
    "            camid = int(img_name.split('_')[1].split('.')[0])\n",
    "            dataset.append((img_path, pid, camid))\n",
    "\n",
    "        return dataset\n",
    "\n",
    "# Register your dataset\n",
    "import torchreid\n",
    "torchreid.data.register_image_dataset('occluded_reid', OccludedREID)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Person Re-identification"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Market-1501 Person Re-identification"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Softmax Loss\n",
    "\n",
    "Change the model name based on what models you would like to use. Refer to the top part for the list of models available. In addition, change the save directory towards what you want also."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datamanager = torchreid.data.ImageDataManager(\n",
    "    root=\"reid-data\",\n",
    "    sources=\"market1501\",\n",
    "    targets=\"market1501\",\n",
    "    height=256,\n",
    "    width=128,\n",
    "    batch_size_train=32,\n",
    "    batch_size_test=100,\n",
    "    transforms=[\"random_flip\", \"random_crop\"]\n",
    ")\n",
    "\n",
    "\n",
    "model = torchreid.models.build_model(\n",
    "    name=\"osnet_x0_75\",\n",
    "    num_classes=datamanager.num_train_pids,\n",
    "    loss=\"softmax\",\n",
    "    pretrained=True\n",
    ")\n",
    "\n",
    "model = model.cuda()\n",
    "\n",
    "optimizer = torchreid.optim.build_optimizer(\n",
    "    model,\n",
    "    optim=\"adam\",\n",
    "    lr=0.0003\n",
    ")\n",
    "\n",
    "scheduler = torchreid.optim.build_lr_scheduler(\n",
    "    optimizer,\n",
    "    lr_scheduler=\"single_step\",\n",
    "    stepsize=20\n",
    ")\n",
    "\n",
    "engine = torchreid.engine.ImageSoftmaxEngine(\n",
    "    datamanager,\n",
    "    model,\n",
    "    optimizer=optimizer,\n",
    "    scheduler=scheduler,\n",
    "    label_smooth=True\n",
    ")\n",
    "\n",
    "engine.run(\n",
    "    save_dir=\"log/osnet_x0_75_market1501softmax_normalized_310523\",\n",
    "    max_epoch=60,\n",
    "    eval_freq=10,\n",
    "    print_freq=10,\n",
    "    test_only=False,\n",
    "    normalize_feature= True\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Triplet Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datamanager = torchreid.data.ImageDataManager(\n",
    "    root='reid-data',\n",
    "    sources='market1501',\n",
    "    height=256,\n",
    "    width=128,\n",
    "    combineall=False,\n",
    "    batch_size=32,\n",
    "    num_instances=4,\n",
    "    train_sampler='RandomIdentitySampler' # this is important\n",
    ")\n",
    "\n",
    "model = torchreid.models.build_model(\n",
    "    name='osnet_x0_75',\n",
    "    num_classes=datamanager.num_train_pids,\n",
    "    loss='triplet'\n",
    ")\n",
    "model = model.cuda()\n",
    "optimizer = torchreid.optim.build_optimizer(\n",
    "    model, optim='adam', lr=0.0003\n",
    ")\n",
    "scheduler = torchreid.optim.build_lr_scheduler(\n",
    "    optimizer,\n",
    "    lr_scheduler='single_step',\n",
    "    stepsize=20\n",
    ")\n",
    "engine = torchreid.engine.ImageTripletEngine(\n",
    "    datamanager, model, optimizer, margin=0.3,\n",
    "    weight_t=0.7, weight_x=1, scheduler=scheduler\n",
    ")\n",
    "engine.run(\n",
    "    max_epoch=60,\n",
    "    save_dir='log/osnet_x0_75_market1501triplet_normalized_310523',\n",
    "    print_freq=10,\n",
    "    normalize_feature= True\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Occluded-Reid Person Re-identification"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Softmax Loss\n",
    "\n",
    "Again, change the model name based on what you would like to use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torchreid.models.build_model(\n",
    "    name=\"resnet50\",\n",
    "    num_classes=datamanager.num_train_pids,\n",
    "    loss=\"softmax\",\n",
    "    pretrained=True\n",
    ")\n",
    "\n",
    "model = model.cuda()\n",
    "\n",
    "optimizer = torchreid.optim.build_optimizer(\n",
    "    model,\n",
    "    optim=\"adam\",\n",
    "    lr=0.0003\n",
    ")\n",
    "\n",
    "scheduler = torchreid.optim.build_lr_scheduler(\n",
    "    optimizer,\n",
    "    lr_scheduler=\"single_step\",\n",
    "    stepsize=20\n",
    ")\n",
    "\n",
    "engine = torchreid.engine.ImageSoftmaxEngine(\n",
    "    datamanager,\n",
    "    model,\n",
    "    optimizer=optimizer,\n",
    "    scheduler=scheduler,\n",
    "    label_smooth=True\n",
    ")\n",
    "\n",
    "engine.run(\n",
    "    save_dir=\"log/resnet50_market1501triplet_papersetting_090623\",\n",
    "    max_epoch=100,\n",
    "    eval_freq=10,\n",
    "    print_freq=10,\n",
    "    test_only=False,\n",
    "    normalize_feature= True\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Triplet Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torchreid.models.build_model(\n",
    "    name='resnet50mid',\n",
    "    num_classes=datamanager.num_train_pids,\n",
    "    loss='triplet'\n",
    ")\n",
    "model = model.cuda()\n",
    "optimizer = torchreid.optim.build_optimizer(\n",
    "    model, optim='adam', lr=0.0003,\n",
    ")\n",
    "scheduler = torchreid.optim.build_lr_scheduler(\n",
    "    optimizer,\n",
    "    lr_scheduler='single_step',\n",
    "    stepsize=20\n",
    ")\n",
    "engine = torchreid.engine.ImageTripletEngine(\n",
    "    datamanager, model, optimizer, margin=0.3,\n",
    "    weight_t=0.7, weight_x=1, scheduler=scheduler\n",
    ")\n",
    "engine.run(\n",
    "    max_epoch=100,\n",
    "    save_dir='log/resnet50mid_forgettingbest',\n",
    "    normalize_feature= True\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ensemble Learning Person Re-identification"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Market-1501 Ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract features from the testing data\n",
    "test_loaders = datamanager.test_loader\n",
    "\n",
    "query_loader = test_loaders['market1501']['query']\n",
    "gallery_loader = test_loaders['market1501']['gallery']\n",
    "\n",
    "\n",
    "#Define extractor\n",
    "extractor1 = FeatureExtractor(model_path='log/osnet_x1_0_market1501final/model/model.pth.tar-100', model_name='osnet_x1_0', device='cuda')\n",
    "use_gpu = torch.cuda.is_available()\n",
    "\n",
    "extractor2  = FeatureExtractor(model_path='log/osnet_x0_75_market1501final/model/model.pth.tar-100', model_name='osnet_x0_75', device='cuda')\n",
    "\n",
    "@torch.no_grad()\n",
    "def feature_extraction(data_loader, extractor, use_gpu):\n",
    "    f_, pids_, camids_ = [], [], []\n",
    "    for batch_idx, data in enumerate(data_loader):\n",
    "        imgs = data['img']\n",
    "        pids = data['pid']\n",
    "        camids = data['camid']\n",
    "        if use_gpu:\n",
    "            imgs = imgs.cuda()\n",
    "        features = extractor(imgs)  # use the extractor instance directly\n",
    "        features = features.cpu()\n",
    "        f_.append(features)\n",
    "        pids_.extend(pids.tolist())\n",
    "        camids_.extend(camids.tolist())\n",
    "    f_ = torch.cat(f_, 0)\n",
    "    pids_ = np.asarray(pids_)\n",
    "    camids_ = np.asarray(camids_)\n",
    "    return f_, pids_, camids_\n",
    "\n",
    "#Extracting features using extractor1\n",
    "print('Extracting features from query set ...')\n",
    "qf, q_pids, q_camids = feature_extraction(query_loader, extractor1, use_gpu)\n",
    "print('Done, obtained {}-by-{} matrix'.format(qf.size(0), qf.size(1)))\n",
    "\n",
    "print('Extracting features from gallery set ...')\n",
    "gf, g_pids, g_camids = feature_extraction(gallery_loader, extractor1, use_gpu)\n",
    "print('Done, obtained {}-by-{} matrix'.format(gf.size(0), gf.size(1)))\n",
    "\n",
    "#Extracting features using extractor2\n",
    "print('Extracting features from query set ...')\n",
    "qf2, q_pids2, q_camids2 = feature_extraction(query_loader, extractor2, use_gpu)\n",
    "print('Done, obtained {}-by-{} matrix'.format(qf.size(0), qf.size(1)))\n",
    "\n",
    "print('Extracting features from gallery set ...')\n",
    "gf2, g_pids2, g_camids2 = feature_extraction(gallery_loader, extractor2, use_gpu)\n",
    "print('Done, obtained {}-by-{} matrix'.format(gf.size(0), gf.size(1)))\n",
    "\n",
    "qf_avg = (qf + qf2  ) / 2\n",
    "gf_avg = (gf + gf2 ) / 2\n",
    "\n",
    "#Compute distance matrix for extractor1\n",
    "print('Computing distance matrix with metric={} ...'.format(\"euclidean\"))\n",
    "distmat = metrics.compute_distance_matrix(qf_avg, gf_avg, metric=\"euclidean\")\n",
    "distmat = distmat.numpy()\n",
    "\n",
    "\n",
    "\n",
    "print('Computing CMC and mAP ...')\n",
    "cmc, mAP = metrics.evaluate_rank(\n",
    "    distmat,\n",
    "    q_pids,\n",
    "    g_pids,\n",
    "    q_camids,\n",
    "    g_camids,\n",
    ")\n",
    "\n",
    "# print results\n",
    "print(f\"mAP: {mAP:.1%}, Rank-1: {cmc[0]:.1%}, Rank-5: {cmc[4]:.1%}, Rank-10: {cmc[9]:.1%},Rank-20: {cmc[19]:.1%}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Occluded-Reid Ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchreid.models import build_model\n",
    "import torch.nn as nn\n",
    "from torchreid.utils import FeatureExtractor\n",
    "from torch.nn import functional as F\n",
    "import numpy as np\n",
    "from torchreid import metrics\n",
    "\n",
    "# Extract features from the testing data\n",
    "test_loaders = datamanager.test_loader\n",
    "\n",
    "query_loader = test_loaders['occluded_reid']['query']\n",
    "gallery_loader = test_loaders['occluded_reid']['gallery']\n",
    "\n",
    "\n",
    "#Define extractor\n",
    "extractor1 = FeatureExtractor(model_path='log/densenet169_ocreidfinal/model/model.pth.tar-100', model_name='densenet169', device='cuda')\n",
    "use_gpu = torch.cuda.is_available()\n",
    "\n",
    "extractor2  = FeatureExtractor(model_path='log/densenet161_ocreidfinal/model/model.pth.tar-100', model_name='densenet161', device='cuda')\n",
    "\n",
    "@torch.no_grad()\n",
    "def feature_extraction(data_loader, extractor, use_gpu):\n",
    "    f_, pids_, camids_ = [], [], []\n",
    "    for batch_idx, data in enumerate(data_loader):\n",
    "        imgs = data['img']\n",
    "        pids = data['pid']\n",
    "        camids = data['camid']\n",
    "        if use_gpu:\n",
    "            imgs = imgs.cuda()\n",
    "        features = extractor(imgs)  # use the extractor instance directly\n",
    "        features = features.cpu()\n",
    "        f_.append(features)\n",
    "        pids_.extend(pids.tolist())\n",
    "        camids_.extend(camids.tolist())\n",
    "    f_ = torch.cat(f_, 0)\n",
    "    pids_ = np.asarray(pids_)\n",
    "    camids_ = np.asarray(camids_)\n",
    "    return f_, pids_, camids_\n",
    "\n",
    "#Extracting features using extractor1\n",
    "print('Extracting features from query set ...')\n",
    "qf, q_pids, q_camids = feature_extraction(query_loader, extractor1, use_gpu)\n",
    "print('Done, obtained {}-by-{} matrix'.format(qf.size(0), qf.size(1)))\n",
    "\n",
    "print('Extracting features from gallery set ...')\n",
    "gf, g_pids, g_camids = feature_extraction(gallery_loader, extractor1, use_gpu)\n",
    "print('Done, obtained {}-by-{} matrix'.format(gf.size(0), gf.size(1)))\n",
    "\n",
    "\n",
    "\n",
    "#Extracting features using extractor2\n",
    "print('Extracting features from query set ...')\n",
    "qf2, q_pids2, q_camids2 = feature_extraction(query_loader, extractor2, use_gpu)\n",
    "print('Done, obtained {}-by-{} matrix'.format(qf.size(0), qf.size(1)))\n",
    "\n",
    "print('Extracting features from gallery set ...')\n",
    "gf2, g_pids2, g_camids2 = feature_extraction(gallery_loader, extractor2, use_gpu)\n",
    "print('Done, obtained {}-by-{} matrix'.format(gf.size(0), gf.size(1)))\n",
    "\n",
    "\n",
    "qf_avg = (qf + qf2  ) / 2\n",
    "gf_avg = (gf + gf2 ) / 2\n",
    "\n",
    "#Compute distance matrix for extractor1\n",
    "print('Computing distance matrix with metric={} ...'.format(\"euclidean\"))\n",
    "distmat = metrics.compute_distance_matrix(qf_avg, gf_avg, metric=\"euclidean\")\n",
    "distmat = distmat.numpy()\n",
    "\n",
    "\n",
    "\n",
    "print('Computing CMC and mAP ...')\n",
    "cmc, mAP = metrics.evaluate_rank(\n",
    "    distmat,\n",
    "    q_pids,\n",
    "    g_pids,\n",
    "    q_camids,\n",
    "    g_camids,\n",
    ")\n",
    "\n",
    "print(\"This is cmc\",cmc)\n",
    "# print results\n",
    "print(f\"mAP: {mAP:.1%}, Rank-1: {cmc[0]:.1%}, Rank-5: {cmc[4]:.1%}, Rank-10: {cmc[9]:.1%}, Rank-20: {cmc[19]:.1%}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torchreid2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
